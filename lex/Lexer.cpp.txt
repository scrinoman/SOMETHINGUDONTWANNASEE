		if (!isMultilineComment && line[i] == '\"' && (i == 0 || (line[i - 1] != '\\' && line[i - 1] != '\'')))
		{
			inString = !inString;
			sourceLine += '"';
			continue;
		}

		if (!inString)
		{
			if (!isMultilineComment)
			{
				if (line[i] == '/' && i < line.length() - 1)
				{
					if (line[i + 1] == '/')
					{
						break;
					}

					if (line[i + 1] == '*')
					{
						isMultilineComment = true;
					}
				}

				if (!isMultilineComment)
				{
					sourceLine += line[i];
				}
			}
			else
			{
				if (i > 0 && line[i] == '/' && line[i - 1] == '*')
				{
					isMultilineComment = false;
				}
			}
		}
		else
		{
			if (!isMultilineComment)
			{
				sourceLine += line[i];
			}
		}
	}

	return sourceLine;
}

vector<SourceLine> ReadAllLines(ifstream &fin)
{
	vector<SourceLine> lines;
	string line;
	bool isMultilineComment = false, inString = false;
	size_t curRow = 1;
	while (getline(fin, line))
	{
		auto &newLine = ProceedLine(line, isMultilineComment, inString);
		//if (!newLine.empty())
		{
			lines.push_back(SourceLine(curRow++, newLine));
		}
	}

	return lines;
}

set<string>::const_iterator FindDelimiter(const string &s, size_t start)
{
	set<string>::const_iterator result = delimiters.cend();
	for (auto &delim : delimiters)
	{
		if (start + delim.length() <= s.length())
		{
			auto new_it = delimiters.find(s.substr(start, delim.length()));
			if (new_it != delimiters.end() && ((result == delimiters.end()) || (new_it->length() > result->length())))
			{
				result = new_it;
			}
		}
	}

	return result;
}

bool DetermineTokenType(const string &token, TokenType &newTokenType)
{
	static const vector<TokenType> complexTokens =
		{ TokenType::IDENTIFIER, TokenType::INTEGER_DEC_NUMBER, TokenType::INTEGER_HEX_NUMBER, TokenType::INTEGER_OCT_NUMBER,
		TokenType::FLOAT_NUMBER, TokenType::CHARACTER, TokenType::STRING };

	if (reservedTokens.find(token) != reservedTokens.end())
	{
		newTokenType = reservedTokens[token];
		return true;
	}
	else
	{
		for (auto &tokenType : complexTokens)
		{
			if (tokenFunc[tokenType](token))
			{
				newTokenType = tokenType;
				return true;
			}
		}
	}

	return false;
}

bool DetermineToken(const string &token, Token &newToken)
{
	if (token != "")
	{
		TokenType type;
		if (DetermineTokenType(token, type))
		{
			newToken = Token(token, type);
			return true;
		}
	}
	else
	{
		return true;
	}

	newToken = Token(token, TokenType::ERROR);
	return false;
}

vector<Token> RecognizeTokens(const string &token)
{
	vector<Token> res;
	string curToken = "";
	bool found = false, inString = false, inChar = false;

	for (size_t i = 0; i < token.length(); ++i)
	{
		bool stringChanged = false, charChanged = false;
		if (!inChar && token[i] == '\"' && (i == 0 || (token[i - 1] != '\\')))
		{
			stringChanged = true;
			inString = !inString;
		}
		if (!inString && token[i] == '\'' && (i == 0 || (token[i - 1] != '\\')))
		{
			charChanged = true;
			inChar = !inChar;
		}

		set<string>::const_iterator it = inString || inChar || (!inString && stringChanged) || (!inChar && charChanged) ? delimiters.cend() 
										: FindDelimiter(token, i);

		if (it != delimiters.end())
		{
			Token newToken("", TokenType::ERROR);
			found = DetermineToken(curToken, newToken);

			if (*it == "+" || *it == "-" || *it == ".")
			{
				if (newToken.type != TokenType::IDENTIFIER)
				{
					curToken += token[i];
					continue;
				}
			}

			if (curToken != "")
			{
				res.push_back(newToken);
			}
			if (found)
			{
				res.push_back(Token(*it, reservedTokens[*it]));
				i += (it->length() - 1);
				curToken = "";
			}
			else
			{
				return res;
			}
		}
		else
		{
			curToken += token[i];
		}
	}
	
	if (curToken != "")
	{
		Token newToken("", TokenType::ERROR);
		found = DetermineToken(curToken, newToken);
		res.push_back(newToken);
	}

	return res;
}

pair<vector<Token>, size_t> GetToken(const vector<SourceLine> &lines, size_t index, size_t position, bool getDelimeter)
{
	bool got = false, inString = false;
	string curToken = "";
	size_t i = position;
	vector<Token> tokens;

	while (!got && index < lines.size())
	{
		auto &line = lines[index].line;
		for (; i < line.length(); ++i)
		{
			if (line[i] == '\"' && (i == 0 || (line[i - 1] != '\\' || line[i - 1] != '\'')))
			{
				inString = !inString;
			}

			if (!inString && whitespaces.find(line[i]) != whitespaces.end())
			{
				got = true;
				break;
			}
			else
			{
				curToken += line[i];
			}
		}

		index++;
		if (!got)
		{
			if (line.length() > 0 && line[line.length() - 1] == '\\')
			{
				i = 0;
			}
			else
			{
				break;
			}
		}
	}

	return make_pair(RecognizeTokens(curToken), i);
}


void ParseFile(const string &fNameInput, const string &fNameOutput)
{
	ifstream inStream(fNameInput);
	ofstream outStream(fNameOutput);

	auto &lines = ReadAllLines(inStream);

	for (size_t i = 0; i < lines.size(); ++i)
	{
		size_t position = 0;
		while (position < lines[i].line.length())
		{
			auto &tokenPair = GetToken(lines, i, position, true);
			position = tokenPair.second + 1;
			for (auto &token : tokenPair.first)
			{
				outStream << lines[i].row << " " << tokenString[token.type] << " " << token.token << endl;
				if (token.type == TokenType::ERROR)
				{
					return;
				}
			}
		}
	}
}